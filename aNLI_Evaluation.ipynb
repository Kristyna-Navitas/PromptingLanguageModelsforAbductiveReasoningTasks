{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9c0183",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c90ec80c-77eb-4d75-a450-61a0800a6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TO_RUN_PATH = 'anli_falcon_inst_zero_shot_diff2.csv'\n",
    "MODEL_TO_RUN_PATH2 = 'anli_gpt2_CoT1.csv'\n",
    "# for consistency voting\n",
    "MODEL_TO_RUN_PATH3 = 'anli_gpt2_CoT3.csv'\n",
    "\n",
    "# consistency_zero, zero_shot, few_shot, new_prompt, CoT_zero, CoT_few\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a40825",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f8d14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "#import re\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f700f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    lines = []\n",
    "    with open(path) as file:\n",
    "        lines = file.read().splitlines()\n",
    "\n",
    "    return pd.DataFrame([json.loads(line) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4011e9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data length: 3059\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>obs1</th>\n",
       "      <th>obs2</th>\n",
       "      <th>hyp1</th>\n",
       "      <th>hyp2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87aa0983-9b84-48b1-86ff-160b1567487c-1</td>\n",
       "      <td>Jane was a professor teaching piano to students.</td>\n",
       "      <td>Jane spent the morning sipping coffee and reading a book.</td>\n",
       "      <td>Two of Jane's students were early for their lessons.</td>\n",
       "      <td>None of Jane's students had a lesson that day.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dfc8584e-13fe-4e26-bdf6-2485e90ef29d-1</td>\n",
       "      <td>Nate had the summer off before college.</td>\n",
       "      <td>Nate's last summer before college was a total blast!</td>\n",
       "      <td>Nate spent the summer traveling and partying.</td>\n",
       "      <td>Nate decided to spend the entire summer working in the Mines.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 story_id  \\\n",
       "0  87aa0983-9b84-48b1-86ff-160b1567487c-1   \n",
       "1  dfc8584e-13fe-4e26-bdf6-2485e90ef29d-1   \n",
       "\n",
       "                                               obs1  \\\n",
       "0  Jane was a professor teaching piano to students.   \n",
       "1           Nate had the summer off before college.   \n",
       "\n",
       "                                                        obs2  \\\n",
       "0  Jane spent the morning sipping coffee and reading a book.   \n",
       "1       Nate's last summer before college was a total blast!   \n",
       "\n",
       "                                                   hyp1  \\\n",
       "0  Two of Jane's students were early for their lessons.   \n",
       "1         Nate spent the summer traveling and partying.   \n",
       "\n",
       "                                                            hyp2  label  \n",
       "0                 None of Jane's students had a lesson that day.      2  \n",
       "1  Nate decided to spend the entire summer working in the Mines.      1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aNLIPath = ''\n",
    "\n",
    "aNLI_test = load_jsonl(aNLIPath+'/test.jsonl')\n",
    "label_test = pd.read_csv(aNLIPath+'/test-labels.lst', header=None, names=['label'])\n",
    "aNLI_test = aNLI_test.join(label_test)\n",
    "print('test data length:', len(aNLI_test))\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "aNLI_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ddd9bfd7-e0d2-4f62-91b2-27d2fa4d738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aNLI_train = load_jsonl(aNLIPath+'/train.jsonl')\n",
    "label_train = pd.read_csv(aNLIPath+'/train-labels.lst', header=None, names=['label'])\n",
    "aNLI_train = aNLI_train.join(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9238116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(path, test_set):\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.merge(test_set, on='story_id')\n",
    "    data['answer'] = data['answer'].apply(lambda x: str(x).replace('[\"', '').replace('\"]',''))\n",
    "    data['answer'] = data['answer'].apply(lambda x: str(x).replace(\"['\", '').replace(\"']\",''))\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b92bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = make_dataset(MODEL_TO_RUN_PATH, aNLI_test)\n",
    "if MODEL_TO_RUN_PATH2:\n",
    "    answers2 = make_dataset(MODEL_TO_RUN_PATH2, aNLI_test)\n",
    "else:\n",
    "    answers2 = pd.DataFrame({'story_id':[], 'obs1':[], 'obs2':[], 'hyp1':[], 'hyp2':[], 'label':[]})\n",
    "if MODEL_TO_RUN_PATH3:\n",
    "    answers3 = make_dataset(MODEL_TO_RUN_PATH3, aNLI_test)\n",
    "else:\n",
    "    answers3 = pd.DataFrame({'story_id':[], 'obs1':[], 'obs2':[], 'hyp1':[], 'hyp2':[], 'label':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b48b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Categorizing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3abb804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "448db51c-7d26-4986-9418-c45075de5b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsimilar_answers = []\\ncor = 0\\n\\nfor i, row in aNLI_test.iterrows():\\n    context = model.encode(row.obs1 + ' ' + row.obs2)\\n    passage_embedding = model.encode([row.hyp1, row.hyp2])\\n    score = util.dot_score(context, passage_embedding)[0]\\n    if score[0] > score[1]:\\n        similar_answers.append(1)\\n        if row.label == 1:\\n            cor += 1\\n    elif score[0] < score[1]:\\n        similar_answers.append(2)\\n        if row.label == 2:\\n            cor +=1\\n        \\n    else:  \\n        print(score)\\n\\nprint(cor)\\nprint(round(cor/len(aNLI_test),3))\\n\\npd.DataFrame(similar_answers).to_csv('similarity_answers')\\n\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "similar_answers = []\n",
    "cor = 0\n",
    "\n",
    "for i, row in aNLI_test.iterrows():\n",
    "    context = model.encode(row.obs1 + ' ' + row.obs2)\n",
    "    passage_embedding = model.encode([row.hyp1, row.hyp2])\n",
    "    score = util.dot_score(context, passage_embedding)[0]\n",
    "    if score[0] > score[1]:\n",
    "        similar_answers.append(1)\n",
    "        if row.label == 1:\n",
    "            cor += 1\n",
    "    elif score[0] < score[1]:\n",
    "        similar_answers.append(2)\n",
    "        if row.label == 2:\n",
    "            cor +=1\n",
    "        \n",
    "    else:  \n",
    "        print(score)\n",
    "\n",
    "print(cor)\n",
    "print(round(cor/len(aNLI_test),3))\n",
    "\n",
    "pd.DataFrame(similar_answers).to_csv('similarity_answers')\n",
    "\"\"\"\n",
    "#0.541 with only similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72498549-e581-49c4-89ce-dec86b845f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_substrings(string):\n",
    "    irrelevant_strings = ['the simple explanation is:', 'the simple explanation is ', 'the explanation is:', 'the explanation is ',\n",
    "                         'the explanation is:', 'the explanation is ']\n",
    "    for substr in irrelevant_strings:\n",
    "        if substr in string:\n",
    "            string = string.replace(substr, '')\n",
    "            \n",
    "    return string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37311e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_it(data):\n",
    "    answers_label = []\n",
    "\n",
    "    \n",
    "    \n",
    "    formulations_A_check= ['the correct answer is a','the correct choice is: a', 'the more likely explanation is a', \n",
    "                   'correct scenario is a', 'a is more likely', 'scenario a is more likely', 'a. is more likely',\n",
    "                     '<strong>scenario a</strong>', 'correct scenario is a', 'a is the more likely', 'a) is the more likely',\n",
    "                     'the more likely explanation is choice a', 'the more likely one is hypothesis a', 'a is more likely',\n",
    "                     'more likely explanation is hypothesis a', 'more likely explanation is that a', 'a seems more likely',\n",
    "                     'a) is more likely', 'the answer is: a', 'the correct hypothesis is a', 'more similar to the context is text a',\n",
    "                     'the context is better explained by hypothesis a.', 'the answer is a', 'scenario a', 'the answer: a', 'answer: (a)', \n",
    "                       'a.', '(a)', \"'a'\", '(1)', '1.', 'h1','hypothesis a','text a', 'a. answers the question', 'a. relates better',\n",
    "                     'a is more similar', 'case a', 'option a', 'first one is more similar', 'a is more consistent', 'a. is correct',\n",
    "                          'yes, hypothesis b'] # contradicts context\n",
    "    formulations_B_check = ['the correct answer is b','the correct choice is: b', 'the more likely explanation is b', \n",
    "                            'correct scenario is b', 'b is more likely', 'scenario b is more likely', 'b. is more likely',\n",
    "                     '<strong>scenario b</strong>', 'correct scenario is b', 'b is the more likely', 'b) is the more likely',\n",
    "                     'the more likely explanation is choice b', ' the more likely one is hypothesis b', 'b is more likely',\n",
    "                     'more likely explanation is hypothesis b', 'more likely explanation is that b', 'b seems more likely',\n",
    "                     'b) is more likely', 'the answer is: b', 'the correct hypothesis is b', 'more similar to the context is text b',\n",
    "                     'the context is better explained by hypothesis a.', 'the answer is b', 'scenario b', 'the answer: b', 'answer: (b)', \n",
    "                        'b.', '(b)',\"'b'\", '(2)', '2.', 'h2', 'hypothesis b','text b', 'b. answers the question','b. relates better',\n",
    "                     'b is more similar', 'case b', 'option b', 'second one is more similar','b is more consistent', 'b. is correct',\n",
    "                           'yes, hypothesis a']\n",
    "\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        # just don't want to deal with casing\n",
    "        answ, hyp1, hyp2 = str(row.answer).lower(), row.hyp1.lower(), row.hyp2.lower()\n",
    "        answ = answ.replace(row.obs1.lower(), '')\n",
    "        answ = answ.replace(row.obs2.lower(), '')\n",
    "\n",
    "        answ = answ.split('the context is:', 1)[0]\n",
    "\n",
    "        answer_found = False\n",
    "    \n",
    "        # if it told just the letter/number of of hypothesis (T5)\n",
    "        if answ=='a' or answ=='1' or answ=='a.' or answ=='\\na':\n",
    "            answers_label.append(1)\n",
    "            continue\n",
    "        elif answ=='b' or answ==2 or answ=='b.' or answ=='\\nb':\n",
    "            answers_label.append(2)\n",
    "            continue\n",
    "        elif answ=='':\n",
    "            answers_label.append(0)\n",
    "            continue\n",
    "\n",
    "        # have to check if there aren't both\n",
    "        for s in range(len(formulations_A_check)):\n",
    "            if (formulations_A_check[s] in answ) and (formulations_B_check[s] not in answ):\n",
    "                answers_label.append(1)\n",
    "                answer_found = True\n",
    "                break\n",
    "            elif (formulations_B_check[s] in answ) and (formulations_A_check[s] not in answ):\n",
    "                answers_label.append(2)\n",
    "                answer_found = True\n",
    "                break\n",
    "\n",
    "        if answer_found:\n",
    "            continue\n",
    "\n",
    "        if answ.startswith('\\nthe correct scenario is a'):\n",
    "            answers_label.append(1)\n",
    "            answer_found = True\n",
    "        elif answ.startswith('\\nthe correct scenario is b'):\n",
    "            answers_label.append(2)\n",
    "            answer_found = True\n",
    "        \n",
    "        if answer_found:\n",
    "            continue\n",
    "\n",
    "        # get just what is after this\n",
    "        likely_string='the more likely explanation is that '\n",
    "        likely_string2 = \"it's more likely that \"\n",
    "        if likely_string in answ:\n",
    "            index = answ.find(likely_string)\n",
    "            answ = (answ[index+len(likely_string):])\n",
    "        elif likely_string2 in answ:\n",
    "            index = answ.find(likely_string2)\n",
    "            answ = (answ[index+len(likely_string2):])\n",
    "             \n",
    "        # if it repeated the hypothesis\n",
    "        if ((answ in hyp1[:-1]) and (answ not in hyp2[:-1])) or ((hyp1[:-1] in answ) and (hyp2[:-1] not in answ)):\n",
    "            answers_label.append(1)\n",
    "        elif (answ in hyp2[:-1]) and (answ not in hyp1[:-1]) or ((hyp2[:-1] in answ) and (hyp1[:-1] not in answ)):\n",
    "            answers_label.append(2)\n",
    "                \n",
    "        else:\n",
    "            answ = remove_substrings(answ)\n",
    "            # try to match the longest string between the answer and hypothesis\n",
    "            if answ:\n",
    "                match1_ratio = SequenceMatcher(None, answ, hyp1).find_longest_match()[2]/len(answ)\n",
    "                match2_ratio = SequenceMatcher(None, answ, hyp2).find_longest_match()[2]/len(answ)\n",
    "            else:\n",
    "                match1_ratio, match2_ratio = 0, 0\n",
    "            if match1_ratio > 0.8 and match2_ratio < 0.6:\n",
    "                answers_label.append(1)\n",
    "            elif match2_ratio > 0.8 and match1_ratio < 0.6:\n",
    "                answers_label.append(2)\n",
    "                \n",
    "            else:\n",
    "                # I will use similarity of embeddings to evaluate it\n",
    "                query_embedding = model.encode(answ)\n",
    "                passage_embedding = model.encode([hyp1, hyp2])\n",
    "                score = util.dot_score(query_embedding, passage_embedding)[0]\n",
    "                score1 = float(score[0]) \n",
    "                score2 = float(score[1])\n",
    "\n",
    "                # this should be a good match for one hypothesis\n",
    "                if (score1 > 0.95) and (score2 < 0.8):\n",
    "                    answers_label.append(1)\n",
    "                elif (score2 > 0.95) and (score2 < 0.8):\n",
    "                    answers_label.append(2)\n",
    "\n",
    "                elif score1 > 0.70 and (score1-score2) > 0.2:\n",
    "                    answers_label.append(1)\n",
    "                elif score2 > 0.70 and (score2-score1) > 0.2:\n",
    "                    answers_label.append(2)\n",
    "\n",
    "                # those are mostly just weird and not correct\n",
    "                else:\n",
    "                    answers_label.append(0)\n",
    "\n",
    "    \n",
    "    data['answr_lbl'] = answers_label\n",
    "    answers_correct = len(data.loc[(data['label'] == data['answr_lbl'])])\n",
    "    not_assessed = len(data.loc[(data['answr_lbl'] == 0)])\n",
    "    \n",
    "    #print('correct:', answers_correct, 'all:', len(data), 'percentage correct:', round(answers_correct/len(data),3))\n",
    "    #print('not evaluated:', not_assessed, 'percent:', round(not_assessed/len(data),3) )\n",
    "    \n",
    "    return data, answers_correct/len(data), not_assessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25652ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, correct_num, not_assessed = evaluate_it(answers)\n",
    "\n",
    "if MODEL_TO_RUN_PATH2:\n",
    "    predictions2, correct_num2, not_assessed2 = evaluate_it(answers2)\n",
    "if MODEL_TO_RUN_PATH3:\n",
    "    predictions3, correct_num3, not_assessed3 = evaluate_it(answers3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15715564",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Looking at how it gets stuff right/wrong\n",
    "could it probably just choose the answer that has better similarity with the context?  \n",
    "**T5 large zero-shot**:  \n",
    "* didnt get:  it is only around 2 percent, in the error  \n",
    "    - maybe I could be more benevolent with the similarity? or some hadn't/didn't or maybe tokenize it?\n",
    "    - I also sometimes it just adds some explanation...  \n",
    "    - lot of the errors are that it doesn't get it is searching for an explanation and just gives the result context \n",
    "    - and lot of error is just combination of the two hypothesis \n",
    "* wrong: \n",
    "    - maybe some knowledge about world missing... |\n",
    "    - no reasoning 7\n",
    "    - not easy for me also ||\n",
    "    \n",
    "**T5 large CoT zero-shot**: \n",
    "* right: some of them are wrong as I'm not generating the whole answer! - SOLVED\n",
    "* didn't get it: 16% quite a lot!\n",
    "    - combines observations |\n",
    "    - just weird ||\n",
    "    - giving both hypothesis 6\n",
    "    - truncated |\n",
    "* wrong: \n",
    "    - no reasoning 6\n",
    "    - both hypothesis 4\n",
    "\n",
    "**T5 large few-shot** (3): \n",
    "* right: Mostly just the letter for answer; could be quite easily explained with higher similarity score\n",
    "* didn't get it: nothing\n",
    "* wrong:\n",
    "    - same words (maybe negation there...): |\n",
    "    - no reasoning: 8\n",
    "    - i dont get which one: |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9932a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## What is the error for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50cc5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_variation_by_split(dataset, folds):\n",
    "    fold_size = round(len(dataset)/folds)\n",
    "    #print('fold size:', fold_size)\n",
    "    \n",
    "    shuffled = dataset.sample(frac=1)\n",
    "    correct_frac = []\n",
    "\n",
    "    for i in range(folds):\n",
    "        a = shuffled[i*fold_size:(i+1)*fold_size]\n",
    "        gold = list(a.label)\n",
    "        pred = list(a.answr_lbl)\n",
    "\n",
    "        ok = 0\n",
    "        for n in range(len(gold)):\n",
    "            if pred[n] == gold[n]:\n",
    "                ok +=1\n",
    "        if gold:\n",
    "            correct_frac.append(ok/len(gold))\n",
    "        else:\n",
    "            print('ERROR', ok)\n",
    "            correct_frac.append(0)\n",
    "\n",
    "    stderr = np.std(correct_frac)/np.sqrt(folds)*1.96\n",
    "\n",
    "    return correct_frac, stderr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e66cd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not count the not assessed ones for accuracy\n",
    "correct_list, stderr = find_variation_by_split(answers, 30)\n",
    "\n",
    "#print('!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "#print('accuracy:', round(correct_num*100), '+-', round(stderr*100))\n",
    "#print('not assessed: ', round(not_assessed/len(answers),3))\n",
    "#print(len(answers))\n",
    "\n",
    "if MODEL_TO_RUN_PATH2:\n",
    "    correct_list2, stderr2 = find_variation_by_split(answers2, 30)\n",
    "if MODEL_TO_RUN_PATH3:\n",
    "    correct_list3, stderr3 = find_variation_by_split(answers3, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c439536-e459-434a-a8e7-fe68b0aa2070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3058"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers[answers.answr_lbl!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2671f5e-013b-43e2-9515-f34237001d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 answers_sim[<span style=\"color: #808000; text-decoration-color: #808000\">'answ_lbl'</span>] = similar_answers                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>answers_sim                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'similar_answers'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 answers_sim[\u001b[33m'\u001b[0m\u001b[33mansw_lbl\u001b[0m\u001b[33m'\u001b[0m] = similar_answers                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0manswers_sim                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'similar_answers'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#answers_sim['answ_lbl'] = similar_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8bc811-0878-4266-bec2-3efb0e7df4eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Two models for comparison\n",
    "Null hypothesis: There is no significant difference between the accuracy of the two models.   \n",
    "Alternative hypothesis: There is a significant difference between the accuracy of the two models.   \n",
    "A small p value <=0.05; reject the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a8502-2cf5-4a6b-ae1e-f1e406b5d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "davinci = 74.0\n",
    "ChatGPT = 80.9\n",
    "Bard = 75.0\n",
    "BERT = 68.9\n",
    "GPT = 63.1\n",
    "\n",
    "test = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee741435-e5fd-41c5-8561-8894646baf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sample T-test\n",
    "t_stat, p_value = stats.ttest_1samp(correct_list, popmean=ChatGPT)\n",
    "#print('davinci vs model p-value:', p_value)\n",
    "if p_value >= 0.05:\n",
    "    print('no difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2cd05c-7951-49f0-8ce5-321a7af0bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paired Two-Sample T-test\n",
    "t_stat, p_value = stats.ttest_rel(correct_list, correct_list2)\n",
    "t_stat2, p_value2 = stats.ttest_rel(correct_list, correct_list3)\n",
    "t_stat3, p_value3 = stats.ttest_rel(correct_list2, correct_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510caed0-6095-417d-bde2-bdc5268344eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paired Two-Sample T-test\n",
    "t_stat3, p_value3 = stats.ttest_rel(correct_list2, correct_list3)\n",
    "#print(f'p-value btw models: {p_value3:.6f}')\n",
    "#if p_value3 >= 0.05:\n",
    "#    print('no difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d8b0b0-f2b5-4e5b-95bd-79fcf7340738",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Consistency voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a39d21-6a39-475e-ab61-4434e3760cf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one = predictions.answr_lbl.tolist()\n",
    "two = predictions2.answr_lbl.tolist()\n",
    "three = predictions3.answr_lbl.tolist()\n",
    "gold = predictions.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ef383-ef46-4061-8e7d-aa74132351c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "correct = 0\n",
    "R = 0\n",
    "for i in range(len(gold)):\n",
    "    answ_list = [one[i], two[i], three[i]]\n",
    "    if answ_list.count(1) >= 2:\n",
    "        if gold[i] == 1:\n",
    "            correct += 1\n",
    "    elif answ_list.count(2) >= 2:\n",
    "        if gold[i] == 2:\n",
    "            correct += 1\n",
    "    elif answ_list.count(0) >=2:\n",
    "        answ_list.remove(0)\n",
    "        answ_list.remove(0)\n",
    "        if gold[i] == answ_list[0]:\n",
    "            correct += 1\n",
    "    else:\n",
    "        rnd = random.choice([1,2])\n",
    "        R += 1\n",
    "        if gold[i] == rnd:\n",
    "            correct += 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61226a5-8a33-497a-bfee-38f5c0a62e44",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03591542-fcfe-411e-93af-ed3955bed7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST DATASET\n",
      "data lenght: 3059 correct: 1567\n",
      "ACCURACY: 51 +- 2\n",
      "N/A: 1 Percentage N/A: 0.0\n",
      "answer A: 367 answer B: 2691\n",
      "answer ratio: 0.13638052768487552\n",
      "\n",
      "SECOND DATASET\n",
      "data lenght: 600 correct: 210\n",
      "ACCURACY: 35 +- 4\n",
      "N/A: 190 Percentage N/A: 0.317\n",
      "answer A: 149 answer B: 261\n",
      "answer ratio: 0.5708812260536399\n",
      "\n",
      "THIRD DATASET\n",
      "data lenght: 600 correct: 188\n",
      "ACCURACY: 31 +- 4\n",
      "N/A: 229 Percentage N/A: 0.382\n",
      "answer A: 154 answer B: 217\n",
      "answer ratio: 0.7096774193548387\n",
      "\n",
      "p-values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">26</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>()                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'p-values'</span>)                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>26 <span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'model 1 vs model 2:'</span>, p_value)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> p_value &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.05</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'no difference'</span>)                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'model 1 vs model 3:'</span>, p_value2)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'p_value'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m26\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m\u001b[96mprint\u001b[0m()                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m24 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m25 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m'\u001b[0m\u001b[33mp-values\u001b[0m\u001b[33m'\u001b[0m)                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m26 \u001b[96mprint\u001b[0m(\u001b[33m'\u001b[0m\u001b[33mmodel 1 vs model 2:\u001b[0m\u001b[33m'\u001b[0m, p_value)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m27 \u001b[0m\u001b[94mif\u001b[0m p_value >= \u001b[94m0.05\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m'\u001b[0m\u001b[33mno difference\u001b[0m\u001b[33m'\u001b[0m)                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m29 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m'\u001b[0m\u001b[33mmodel 1 vs model 3:\u001b[0m\u001b[33m'\u001b[0m, p_value2)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'p_value'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('FIRST DATASET')\n",
    "print('data lenght:', len(answers), 'correct:', len(answers[answers.label == answers.answr_lbl]))\n",
    "print('ACCURACY:', round(correct_num*100), '+-', round(stderr*100))\n",
    "print('N/A:', not_assessed, 'Percentage N/A:', round(not_assessed/len(answers),3) )\n",
    "print('answer A:', len(predictions[predictions.answr_lbl==1]), 'answer B:', len(predictions[predictions.answr_lbl==2]))\n",
    "print('answer ratio:', len(predictions[predictions.answr_lbl==1])/len(predictions[predictions.answr_lbl==2]))\n",
    "print()\n",
    "\n",
    "print('SECOND DATASET')\n",
    "print('data lenght:', len(answers2), 'correct:', len(answers2[answers2.label == answers2.answr_lbl]))\n",
    "print('ACCURACY:', round(correct_num2*100), '+-', round(stderr2*100))\n",
    "print('N/A:', not_assessed2, 'Percentage N/A:', round(not_assessed2/len(answers2),3) )\n",
    "print('answer A:', len(predictions2[predictions2.answr_lbl==1]), 'answer B:', len(predictions2[predictions2.answr_lbl==2]))\n",
    "print('answer ratio:', len(predictions2[predictions2.answr_lbl==1])/len(predictions2[predictions2.answr_lbl==2]))\n",
    "print()\n",
    "\n",
    "print('THIRD DATASET')\n",
    "print('data lenght:', len(answers3), 'correct:', len(answers3[answers3.label == answers3.answr_lbl]))\n",
    "print('ACCURACY:', round(correct_num3*100), '+-', round(stderr3*100))\n",
    "print('N/A:', not_assessed3, 'Percentage N/A:', round(not_assessed3/len(answers3),3) )\n",
    "print('answer A:', len(predictions3[predictions3.answr_lbl==1]), 'answer B:', len(predictions3[predictions3.answr_lbl==2]))\n",
    "print('answer ratio:', len(predictions3[predictions3.answr_lbl==1])/len(predictions3[predictions3.answr_lbl==2]))\n",
    "print()\n",
    "\n",
    "print('p-values')\n",
    "print('model 1 vs model 2:', p_value)\n",
    "if p_value >= 0.05:\n",
    "    print('no difference')\n",
    "print('model 1 vs model 3:', p_value2)\n",
    "if p_value2 >= 0.05:\n",
    "    print('no difference')\n",
    "print('model 2 vs model 3:', p_value3)\n",
    "if p_value3 >= 0.05:\n",
    "    print('no difference')\n",
    "print()\n",
    "\n",
    "print('CONSISTENCY VOTING')\n",
    "print(round(correct/len(gold),3))\n",
    "print('random',  round(R/len(gold),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c6e4f-1f95-465a-bbb6-653b0bb40b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_look_at = predictions\n",
    "model_to_look_at2 = predictions3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3a368-54e7-4cfe-a57c-833c4295c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity of two models together -> Falcon and GPT not much 53\\%, GPT and LLAMA nope, GPT and T5? base 39\\%, large 43\\%, (x)xl 50:50\n",
    "#chooses the same as similarity???\n",
    "length_classified = 0\n",
    "same = 0\n",
    "for a, b in zip(model_to_look_at2.answr_lbl.tolist(),model_to_look_at.answr_lbl.tolist()):  \n",
    "    if a!=0 and b!=0:\n",
    "        length_classified +=1\n",
    "        if a==b:\n",
    "            same += 1\n",
    "\n",
    "same/length_classified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17933ac9-ff37-4de0-8026-6fae56ccdeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chooses the same as similarity???\n",
    "\n",
    "same = 0\n",
    "for a, b in zip(similar_answers,model_to_look_at.answr_lbl.tolist()):       \n",
    "    if a==b:\n",
    "        same += 1\n",
    "\n",
    "length_classified = len(model_to_look_at[model_to_look_at.answr_lbl!=0])\n",
    "print(length_classified)\n",
    "same/length_classified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a7d94-dc38-4d48-9e88-187aa03257f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes both hypothesis contradict; No hypothesis contradicts the context. \n",
    "#CoT1 #relates better\n",
    "\n",
    "#correct hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc71b8a-e231-4910-baf7-b483b29ed570",
   "metadata": {},
   "outputs": [],
   "source": [
    "suit = model_to_look_at[model_to_look_at.answer.str.contains('relates better', case=False)]\n",
    "#suit = model_to_look_at[model_to_look_at.answr_lbl ==1]\n",
    "#suit = model_to_look_at[model_to_look_at.answr_lbl != model_to_look_at.label]\n",
    "suit.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b44a8d-8b61-4426-98d2-3adf30c21b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(suit[suit.answr_lbl==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34178c03-ef12-4e31-92f8-42f11b585d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'following prompt', len(suit)/len(model_to_look_at),len(suit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb96b1a-e893-43ec-a034-8f9e64486be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'suit accuracy', len(suit[suit.answr_lbl==suit.label])/len(suit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af8c0d-4265-4c41-9490-485cab6e3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_to_look_at[model_to_look_at.hyp1.str.contains('The correct choice is:', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dfb647-547b-42c0-bfc0-cbe5ffccb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what the model got right\n",
    "print(len(model_to_look_at.loc[(model_to_look_at['label'] == model_to_look_at['answr_lbl'])]))\n",
    "right = model_to_look_at.loc[(model_to_look_at['label'] == model_to_look_at['answr_lbl'])]\n",
    "right.sample(5)\n",
    "#right[right.label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5aed24-432e-4744-a3a0-7a557ccfecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what the model got wrong\n",
    "not_NA = model_to_look_at.loc[(model_to_look_at['answr_lbl'] != 0)]\n",
    "print(len(not_NA.loc[(not_NA['label'] != not_NA['answr_lbl'])]))\n",
    "wrong = not_NA.loc[(not_NA['label'] != not_NA['answr_lbl'])]\n",
    "wrong.sample(5)\n",
    "#wrong[wrong.answr_lbl==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d5df4e-cdfc-489d-9fea-bd2b1d052d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what I wasnt able to categorize to answer\n",
    "print(len(model_to_look_at.loc[(model_to_look_at['answr_lbl'] == 0)]))\n",
    "na =  model_to_look_at.loc[(model_to_look_at['answr_lbl'] == 0)]\n",
    "na.sample(5)\n",
    "\n",
    "#na[na.label!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a4e20-3c7f-4102-b47f-83b9ffc29b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_to_look_at[model_to_look_at.answer == 'nan'])/len(model_to_look_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa78db-6d45-4fa6-812e-d60f74d0f763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "\"\"\"To see what changed between the models\"\"\"\n",
    "merged = model_to_look_at.merge(model_to_look_at2, how='outer', on='story_id')\n",
    "different = merged.loc[(merged['answr_lbl_x'] != merged['answr_lbl_y'])]\n",
    "print(len(different[(different['answr_lbl_y']==different['label_y'])]))\n",
    "different[(different['answr_lbl_x']==different['label_x'])].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b322e45-37e0-4653-ab7f-68f1e0533dc8",
   "metadata": {},
   "source": [
    "### Pure A, B and random results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eef44e-aea8-49de-a42a-7670f20a8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pureA = len(aNLI_test[aNLI_test.label==1])/len(aNLI_test)\n",
    "pureB = len(aNLI_test[aNLI_test.label==2])/len(aNLI_test)\n",
    "\n",
    "print('pure A:', round(pureA, 2), 'pure B:', round(pureB,2))\n",
    "# A:55, B 45 for first 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc610f2-6567-4971-a589-3f8c7d5262f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_deviation = []\n",
    "\n",
    "for i in range(30):\n",
    "    random_list = [1]*1530 + [2]*1529\n",
    "    random.shuffle(random_list)\n",
    "    \n",
    "    random_correct = 0\n",
    "    for m, t in zip(random_list, aNLI_test.label.tolist()):\n",
    "        if m==t: random_correct+=1\n",
    "\n",
    "    random_deviation.append(round(random_correct/len(aNLI_test),2))\n",
    "    \n",
    "print(min(random_deviation), max(random_deviation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508308f2-9815-49f2-9fb0-9424571254af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pureA, pureB, random = 0,0,0\n",
    "for label in aNLI_test.label.tolist():\n",
    "    if la\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccd03a-8545-4fe2-a0ae-ea3547d37b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdb6e4-6460-4814-901a-a1eccb248aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288dd980-cd64-4fe8-91b1-a6b8c6255204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedfed0-584b-40c5-bf5b-adf723ce3314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
